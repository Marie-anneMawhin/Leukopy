{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Specific to colab\n# Gives access to the Drive\n# from google.colab import drive\n# drive.mount('/content/drive')\n\n# import tensorflow as tf\n# import sys, os\n\n# # GPU status verification\n# tf.test.gpu_device_name()\n\n# # GPU type verification\n# gpu_info = !nvidia-smi\n# gpu_info = '\\n'.join(gpu_info)\n# if gpu_info.find('failed') >= 0:\n#     print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n#     print('and then re-execute this cell.')\n# else:\n#     print(gpu_info)\n\n# # Need to copy all the files on the local computer\n# !cp -r \"drive/MyDrive/data/main_dataset.zip\" .\n# !unzip main_dataset.zip\n\n# sys.path.append('drive/MyDrive/colab_notebooks/')\n\n!pip install tensorflow_addons\n!pip install vit-keras","metadata":{"_uuid":"711e18d9-58f6-4797-a411-74f828713eae","_cell_guid":"cd68b037-5214-4a17-be03-f12e234346ae","collapsed":false,"executionInfo":{"elapsed":50483,"status":"ok","timestamp":1629100844846,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"fYbwRUcbW5Aw","outputId":"1a69a3c1-46a4-4624-bac5-3ba41180c0d2","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:25:37.565482Z","iopub.execute_input":"2021-08-19T08:25:37.565776Z","iopub.status.idle":"2021-08-19T08:25:52.39233Z","shell.execute_reply.started":"2021-08-19T08:25:37.565705Z","shell.execute_reply":"2021-08-19T08:25:52.391385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vision Transformer (ViT)\n\ninspired by this [notebook](https://www.kaggle.com/raufmomin/vision-transformer-vit-fine-tuning)","metadata":{"_uuid":"3a1211f3-0151-4bb2-b71c-037e2bdf2524","_cell_guid":"cc77844c-95d2-4875-8885-51eb0305d7d4","id":"gCEuCMrHbClc","trusted":true}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n# import cv2\n\nimport sys, os\nfrom pathlib import Path\n# import shutil\n# import glob\n# import itertools\n\n# from sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TerminateOnNaN, EarlyStopping\n\nfrom tensorflow.keras.utils import Sequence\nfrom collections import Counter\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom vit_keras import vit, utils\nfrom vit_keras import visualize\n\nfrom keras.models import load_model\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# sys.path.append('../')\nimport leukopy_lib as leuko\nfrom importlib import reload\n\nreload(leuko)","metadata":{"_uuid":"4d795bd5-1fb6-4b71-bd32-00be32ae8cdd","_cell_guid":"c9680cce-4f0d-4d55-954c-ca8bfa8cbf5f","collapsed":false,"executionInfo":{"elapsed":2351,"status":"ok","timestamp":1629100847189,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"kpBVr-fObCle","outputId":"a5d4096b-6ce9-444b-fe1e-f55f206d6b82","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:25:55.07585Z","iopub.execute_input":"2021-08-19T08:25:55.076177Z","iopub.status.idle":"2021-08-19T08:26:00.953581Z","shell.execute_reply.started":"2021-08-19T08:25:55.076145Z","shell.execute_reply":"2021-08-19T08:26:00.952777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set up","metadata":{"_uuid":"a8a61492-eebc-496a-8cf5-8e426ad27010","_cell_guid":"7b91ea24-32ab-4836-bcbf-96424b4f84dd","id":"UevtYJhvbClg","trusted":true}},{"cell_type":"markdown","source":"## Generate dataframes","metadata":{"_uuid":"a0f359f9-3752-4cd3-9041-41341b9df267","_cell_guid":"6075b994-db45-4083-8473-0ffb23f3454e","id":"i7hOEi3hbClh","trusted":true}},{"cell_type":"code","source":"# pa/kaggle/ = Path('main_dataset/')\npath = Path('../input/main-dataset/main_dataset/')\n\ndf_train = leuko.generate_images_df(path/'training_set')\ndf_test = leuko.generate_images_df(path/'testing_set')\ndf_valid = leuko.generate_images_df(path/'validation_set')\n\ndf_train.head()","metadata":{"_uuid":"c7fbfafa-2750-44f6-911e-43254b66132f","_cell_guid":"cff16ea4-8568-4253-a8bf-65773aaf8092","collapsed":false,"executionInfo":{"elapsed":586,"status":"ok","timestamp":1629100847766,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"p7WEwIzaW6AL","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:26:08.880815Z","iopub.execute_input":"2021-08-19T08:26:08.881152Z","iopub.status.idle":"2021-08-19T08:26:28.921489Z","shell.execute_reply.started":"2021-08-19T08:26:08.881122Z","shell.execute_reply":"2021-08-19T08:26:28.920579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### choose classes","metadata":{"_uuid":"8f32b79a-f2c6-4f65-b3b6-fad01911c80e","_cell_guid":"b79526d5-7f1a-4010-9a8e-8971e1b3f766","id":"Cn76KWlebCli","trusted":true}},{"cell_type":"code","source":"n_classes, df_train, df_test, df_valid = leuko.choose_classes(df_train, df_test, df_valid, n_classes = 11)","metadata":{"_uuid":"77434653-98f9-4251-b1e3-b9b87b5acb34","_cell_guid":"96f6bead-6cb5-4f92-98aa-a6945ff9e17f","collapsed":false,"executionInfo":{"elapsed":223,"status":"ok","timestamp":1629100861053,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"BSIaiEjJW6Jw","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:26:28.925453Z","iopub.execute_input":"2021-08-19T08:26:28.927539Z","iopub.status.idle":"2021-08-19T08:26:28.944573Z","shell.execute_reply.started":"2021-08-19T08:26:28.927497Z","shell.execute_reply":"2021-08-19T08:26:28.94358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes","metadata":{"_uuid":"52e2fba0-1f77-4e75-9987-4b6f110880e8","_cell_guid":"2c1bf5a2-6161-43da-a5e5-b72f45337e80","collapsed":false,"executionInfo":{"elapsed":209,"status":"ok","timestamp":1629100862177,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"vDD0ZlqTeFRD","outputId":"80a08d1f-ca13-45b5-c965-99ec30b81c04","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:26:28.949606Z","iopub.execute_input":"2021-08-19T08:26:28.951705Z","iopub.status.idle":"2021-08-19T08:26:28.961021Z","shell.execute_reply.started":"2021-08-19T08:26:28.951666Z","shell.execute_reply":"2021-08-19T08:26:28.959996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"label\"].value_counts()","metadata":{"_uuid":"1c5a35a5-cbd3-4761-879b-4907a7f6feeb","_cell_guid":"4718775d-acbc-4af9-8a00-18e4ff924b5d","collapsed":false,"executionInfo":{"elapsed":13,"status":"ok","timestamp":1629100863123,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"DhlAMAWLW6Sj","outputId":"8b7e538c-9ef4-4a2f-b163-cbabefe2b631","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:26:28.965459Z","iopub.execute_input":"2021-08-19T08:26:28.96751Z","iopub.status.idle":"2021-08-19T08:26:28.984363Z","shell.execute_reply.started":"2021-08-19T08:26:28.967475Z","shell.execute_reply":"2021-08-19T08:26:28.983347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image generator\n\nFor ViT image are patched into [16x16](https://arxiv.org/abs/2010.11929) images (\"images is worth 16x16 words\")","metadata":{"_uuid":"a914e8b0-e7d0-4cd1-bebb-28349010b7e8","_cell_guid":"5b82c754-0bf5-4f52-b03f-78fdbd7b930d","id":"e8JtHfMvbClk","trusted":true}},{"cell_type":"code","source":"batch_size = 32\nimg_size  = 352 #need to be a multiple of patch size = 16\nepochs=100","metadata":{"_uuid":"40d6f518-a5e3-4e32-9230-c2f5f9cbd52a","_cell_guid":"1f52e981-d0b0-4ba0-a2ea-c48c5d72672a","collapsed":false,"executionInfo":{"elapsed":197,"status":"ok","timestamp":1629100866391,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"3mPZEQjcW6Zl","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:26:28.988593Z","iopub.execute_input":"2021-08-19T08:26:28.990593Z","iopub.status.idle":"2021-08-19T08:26:28.996204Z","shell.execute_reply.started":"2021-08-19T08:26:28.990556Z","shell.execute_reply":"2021-08-19T08:26:28.995347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = ImageDataGenerator(rotation_range = 90,\n                                     horizontal_flip = True, \n                                     vertical_flip = True)\nvalid_generator = ImageDataGenerator()\ntest_generator = ImageDataGenerator()\n\n# Resize pictures, batchs from dataframe\ntraining_set = train_generator.flow_from_dataframe(df_train, \n                                                   directory = None, # uses x_col\n                                                   x_col = 'img_path', \n                                                   y_col = 'label',\n                                                   target_size = (img_size, img_size), \n                                                   color_mode = 'rgb',\n                                                   classes = None,   # uses y_col\n                                                   class_mode = 'categorical', \n                                                   batch_size = batch_size,\n                                                   shuffle = True)\n\nvalidation_set = valid_generator.flow_from_dataframe(df_valid, \n                                                     directory = None, # uses x_col\n                                                     x_col = 'img_path', \n                                                     y_col = 'label',\n                                                     target_size = (img_size, img_size), \n                                                     color_mode = 'rgb',\n                                                     classes = None,   # uses y_col\n                                                     class_mode = 'categorical', \n                                                     batch_size = batch_size, \n                                                     shuffle = True)\n\ntesting_set = test_generator.flow_from_dataframe(df_test, \n                                                 directory = None, # uses x_col\n                                                 x_col = 'img_path', \n                                                 y_col = 'label',\n                                                 target_size = (img_size, img_size),\n                                                 color_mode = 'rgb',\n                                                 classes = None,   # uses y_col\n                                                 class_mode = 'categorical', \n                                                 batch_size = batch_size, \n                                                 shuffle = False)\n\n# Labels/Index connection :\nlabel_map = training_set.class_indices\nprint('Train :', training_set.class_indices)\nprint('Valid :', validation_set.class_indices)\nprint('Test  :', testing_set.class_indices)","metadata":{"_uuid":"f003690b-b783-4f71-9690-6c6a7819c4ed","_cell_guid":"321c762b-48e5-483f-822a-aa69adc482ac","collapsed":false,"executionInfo":{"elapsed":213,"status":"ok","timestamp":1629100868052,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"fDsbzCc9bCll","outputId":"8149d206-cee7-4633-e4ce-efb8a946997c","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:33:11.648527Z","iopub.execute_input":"2021-08-19T08:33:11.648891Z","iopub.status.idle":"2021-08-19T08:33:19.558727Z","shell.execute_reply.started":"2021-08-19T08:33:11.648856Z","shell.execute_reply":"2021-08-19T08:33:19.557811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = [training_set[0][0][i] for i in range(5)]\nfig, axes = plt.subplots(2, 2, figsize = (10, 10))\n\naxes = axes.flatten()\n\nfor img, ax in zip(images, axes):\n    ax.imshow(img.reshape(img_size, img_size, 3).astype('uint8'))\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"2e42bea8-35db-404f-a3de-be30523645a8","_cell_guid":"6e6cba09-ac52-40a1-9f8f-7bd056c8c173","collapsed":false,"executionInfo":{"elapsed":5223,"status":"ok","timestamp":1629100876171,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"H0VGWggubClm","outputId":"becb755c-945b-45e6-ca54-23c31c02e6df","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ViT model set up","metadata":{"_uuid":"218e3e46-45e8-42f8-b6d6-8b326202fcdb","_cell_guid":"8c431719-d5eb-423a-a22f-ca8860e012c6","id":"a-S21P-sbCln","trusted":true}},{"cell_type":"code","source":"# classes = utils.get_imagenet_classes()\n\nvit_model = vit.vit_b32(\n    weights='imagenet21k+imagenet2012',\n        image_size = img_size,\n        activation = 'softmax',\n        pretrained = True,\n        include_top = False,\n        pretrained_top = False,\n        classes = n_classes)\n\n# image_size = 384\n# classes = utils.get_imagenet_classes()\n# model = vit.vit_b16(\n#     image_size=image_size,\n#     activation='sigmoid',\n#     pretrained=True,\n#     include_top=True,\n#     pretrained_top=True\n# )\n# url = 'https://upload.wikimedia.org/wikipedia/commons/d/d7/Granny_smith_and_cross_section.jpg'\n# image = utils.read(url, image_size)\n# X = vit.preprocess_inputs(image).reshape(1, image_size, image_size, 3)\n# y = model.predict(X)\n# print(classes[y[0].argmax()]) # Granny smith","metadata":{"_uuid":"d8d98cc9-a66b-4cc2-a2b9-6cf6023ae359","_cell_guid":"506c3861-95b0-440f-9f50-896363aa5582","collapsed":false,"executionInfo":{"elapsed":6818,"status":"ok","timestamp":1629100882982,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"y0BxMt03bCln","outputId":"17e6d6d4-6105-4e70-fc7a-97876bc5f628","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:33:24.218134Z","iopub.execute_input":"2021-08-19T08:33:24.218542Z","iopub.status.idle":"2021-08-19T08:33:27.452136Z","shell.execute_reply.started":"2021-08-19T08:33:24.218505Z","shell.execute_reply":"2021-08-19T08:33:27.451306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = testing_set.next()\nimage = x[0][0]\n\nattention_map = visualize.attention_map(model = vit_model, image = image)\n\n# Plot results\nfig, (ax1, ax2) = plt.subplots(ncols = 2)\nax1.axis('off')\nax2.axis('off')\nax1.set_title('Original')\nax2.set_title('Attention Map')\n_ = ax1.imshow(image.astype('uint8'))\n_ = ax2.imshow(attention_map)","metadata":{"_uuid":"f3f2c55c-b33a-436e-bfe3-dcece4d18fc2","_cell_guid":"4c587d26-8bb8-4264-ad2d-4d62b597de9a","collapsed":false,"executionInfo":{"elapsed":43723,"status":"ok","timestamp":1629100926694,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"BXHm7JZdbClo","outputId":"ac0c04f7-38ff-4260-8a08-95f5e8b6b839","tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T16:55:20.345552Z","iopub.execute_input":"2021-08-19T16:55:20.34597Z","iopub.status.idle":"2021-08-19T16:55:20.406668Z","shell.execute_reply.started":"2021-08-19T16:55:20.345853Z","shell.execute_reply":"2021-08-19T16:55:20.405574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n        vit_model,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(64, activation = tfa.activations.gelu),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(11, 'softmax')\n    ],\n    name = 'vision_transformer')\n\nmodel.summary()","metadata":{"_uuid":"84e7438a-1837-4ac9-8d9b-ef804f22c2eb","_cell_guid":"ad7bc5d0-e11d-49aa-bbf2-7f912c1cbc8b","collapsed":false,"executionInfo":{"elapsed":1715,"status":"ok","timestamp":1629100932761,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"jGM95UvKbClp","outputId":"b4d2fac1-d96b-4064-8368-41fbe0ebdfa7","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:33:34.528762Z","iopub.execute_input":"2021-08-19T08:33:34.529089Z","iopub.status.idle":"2021-08-19T08:33:35.88621Z","shell.execute_reply.started":"2021-08-19T08:33:34.52906Z","shell.execute_reply":"2021-08-19T08:33:35.885464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1e-3\n\noptimizer = tfa.optimizers.RectifiedAdam(learning_rate = learning_rate)\n\nmodel.compile(optimizer = optimizer, \n              loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2), \n              metrics = ['accuracy'])","metadata":{"_uuid":"b5f81c7c-dd28-45b3-a77d-6758954dd12f","_cell_guid":"3846e1d4-6ce4-4c38-a356-9aca6ca56449","collapsed":false,"executionInfo":{"elapsed":188,"status":"ok","timestamp":1629100935493,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"eegQLj0UbClp","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:33:45.708808Z","iopub.execute_input":"2021-08-19T08:33:45.709147Z","iopub.status.idle":"2021-08-19T08:33:45.72841Z","shell.execute_reply.started":"2021-08-19T08:33:45.709116Z","shell.execute_reply":"2021-08-19T08:33:45.727333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callbacks\n\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',\n                                                 factor = 0.2,\n                                                 patience = 2,\n                                                 verbose = 1,\n                                                 min_delta = 1e-4,\n                                                 min_lr = 1e-6,\n                                                 mode = 'max')\n\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n                                                 min_delta = 1e-4,\n                                                 patience = 5,\n                                                 mode = 'max',\n                                                 restore_best_weights = True,\n                                                 verbose = 1)\n\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = '../working/model_saved/model.hdf5',\n                                                  monitor = 'val_accuracy', \n                                                  verbose = 1, \n                                                  save_best_only = True,\n                                                  save_weights_only = True,\n                                                  mode = 'max')\n\ncallbacks_list = [earlystopping, reduce_lr, checkpointer]","metadata":{"_uuid":"4bba35cd-d2f9-4da4-88cf-24c9ae99c508","_cell_guid":"8773214d-a455-4f28-b6be-904368e71c0b","collapsed":false,"executionInfo":{"elapsed":221,"status":"ok","timestamp":1629100937045,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"6g2ftf8ibClp","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:33:49.917586Z","iopub.execute_input":"2021-08-19T08:33:49.917925Z","iopub.status.idle":"2021-08-19T08:33:49.92515Z","shell.execute_reply.started":"2021-08-19T08:33:49.917894Z","shell.execute_reply":"2021-08-19T08:33:49.924105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n## Compute weights :\n# class_weights = compute_weights(method = 3)\n\n## Training :\nepochs = 100\ntraining_history = model.fit(x = training_set, \n                             steps_per_epoch = training_set.n/training_set.batch_size,\n                             validation_steps = validation_set.n/validation_set.batch_size,\n\n                             epochs = epochs,\n                             callbacks = callbacks_list,\n                             validation_data = validation_set, \n#                              class_weight = class_weights\n                            )\n\nmodel.save('../working/model_saved/model_vit_test')","metadata":{"_uuid":"c2b913c9-f54f-4577-8322-d2fce7f4cfca","_cell_guid":"fcad3a8c-316b-41ee-bf4d-da11e3e454f4","collapsed":false,"executionInfo":{"elapsed":11889435,"status":"error","timestamp":1629113075001,"user":{"displayName":"Leuko PY","photoUrl":"","userId":"08649880194219295972"},"user_tz":-60},"id":"jUTlnLPabClp","outputId":"592662d1-9258-465b-af29-0baf83c27e2f","tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T08:33:58.255116Z","iopub.execute_input":"2021-08-19T08:33:58.255459Z","iopub.status.idle":"2021-08-19T11:48:37.805448Z","shell.execute_reply.started":"2021-08-19T08:33:58.255427Z","shell.execute_reply":"2021-08-19T11:48:37.804549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_history.history","metadata":{"execution":{"iopub.status.busy":"2021-08-19T12:02:13.821637Z","iopub.execute_input":"2021-08-19T12:02:13.821975Z","iopub.status.idle":"2021-08-19T12:02:13.829422Z","shell.execute_reply.started":"2021-08-19T12:02:13.821944Z","shell.execute_reply":"2021-08-19T12:02:13.828414Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_accuracy = training_history.history['accuracy']\nvalidation_accuracy = training_history.history['val_accuracy']\n\nplt.figure()\nplt.plot(np.arange(earlystopping.stopped_epoch), training_accuracy[0:earlystopping.stopped_epoch], label = 'Training Set')\nplt.plot(np.arange(earlystopping.stopped_epoch), validation_accuracy[0:earlystopping.stopped_epoch], label = 'Validation Set')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"_uuid":"7f0ddcb5-70f9-4c82-b196-811b6de38fd9","_cell_guid":"d385e8a3-413b-4da7-92b5-0525a5cb8f84","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T11:58:35.13659Z","iopub.execute_input":"2021-08-19T11:58:35.136922Z","iopub.status.idle":"2021-08-19T11:58:35.292422Z","shell.execute_reply.started":"2021-08-19T11:58:35.136893Z","shell.execute_reply":"2021-08-19T11:58:35.291455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(testing_set)\n","metadata":{"_uuid":"1e0148f6-8892-418a-92ba-bcfce8d3d275","_cell_guid":"d2a49d7d-3d40-4ed1-9c09-0960e9cbb3fc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T11:59:12.171235Z","iopub.execute_input":"2021-08-19T11:59:12.171614Z","iopub.status.idle":"2021-08-19T11:59:40.093834Z","shell.execute_reply.started":"2021-08-19T11:59:12.171581Z","shell.execute_reply":"2021-08-19T11:59:40.093011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(validation_set)","metadata":{"_uuid":"7acac25a-c115-46d6-a359-061e74271220","_cell_guid":"75662de3-4362-4ff0-afa8-709c55dacf08","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T11:59:40.09544Z","iopub.execute_input":"2021-08-19T11:59:40.0958Z","iopub.status.idle":"2021-08-19T11:59:54.472961Z","shell.execute_reply.started":"2021-08-19T11:59:40.095754Z","shell.execute_reply":"2021-08-19T11:59:54.472138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pickle.load(open('../working/model_saved/training_hist', 'rb'))\ntest","metadata":{"execution":{"iopub.status.busy":"2021-08-19T12:05:01.809884Z","iopub.execute_input":"2021-08-19T12:05:01.810209Z","iopub.status.idle":"2021-08-19T12:05:01.819135Z","shell.execute_reply.started":"2021-08-19T12:05:01.810179Z","shell.execute_reply":"2021-08-19T12:05:01.818066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('../working/model_saved/training_hist', 'wb') as f:\n    pickle.dump(training_history.history, f)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T12:03:18.438656Z","iopub.execute_input":"2021-08-19T12:03:18.439021Z","iopub.status.idle":"2021-08-19T12:03:18.444305Z","shell.execute_reply.started":"2021-08-19T12:03:18.438988Z","shell.execute_reply":"2021-08-19T12:03:18.443235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_classes = np.argmax(model.predict(valid_gen, steps = valid_gen.n // valid_gen.batch_size + 1), axis = 1)\ntrue_classes = valid_gen.classes\nclass_labels = list(valid_gen.class_indices.keys())  \n\nconfusionmatrix = confusion_matrix(true_classes, predicted_classes)\nplt.figure(figsize = (16, 16))\nsns.heatmap(confusionmatrix, cmap = 'Blues', annot = True, cbar = True)\n\nprint(classification_report(true_classes, predicted_classes))","metadata":{"_uuid":"ad8a1cc5-6595-4a06-ad49-3afd98fd691d","_cell_guid":"e7c01f54-18d7-4d6b-8810-d9ec7d812ad8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T11:59:54.474648Z","iopub.execute_input":"2021-08-19T11:59:54.475007Z","iopub.status.idle":"2021-08-19T11:59:54.500849Z","shell.execute_reply.started":"2021-08-19T11:59:54.474971Z","shell.execute_reply":"2021-08-19T11:59:54.499366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(validation_set)\ny_pred = tf.argmax(predictions, axis = 1)","metadata":{"_uuid":"8711b2da-9375-4809-9ac5-4b9f23693180","_cell_guid":"7c2c5892-9b69-4373-97f4-9671733dce17","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-08-19T12:00:24.282864Z","iopub.execute_input":"2021-08-19T12:00:24.283192Z","iopub.status.idle":"2021-08-19T12:00:39.535838Z","shell.execute_reply.started":"2021-08-19T12:00:24.283161Z","shell.execute_reply":"2021-08-19T12:00:39.534934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_classes = np.argmax(model.predict(validation_set,\n                                            steps = validation_set.n // validation_set.batch_size + 1), \n                              axis = 1)","metadata":{"_uuid":"9e907092-49fc-440c-9c6b-49fb8e5c5c33","_cell_guid":"75770db8-c550-4d99-80e9-b537fda9786e","collapsed":false,"id":"jUVkMlgObClq","outputId":"2710424b-7d78-469b-c3e6-5e216efaa1e8","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nconfusion_matrix(validation_set.classes, y_pred)","metadata":{"_uuid":"5eb8b96a-bd02-46b4-9bc9-3e0a3459d452","_cell_guid":"2657c963-37d3-42f7-ad36-3661463707bb","collapsed":false,"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n# true_classes = validation_set.classes\n# class_labels = list(validation_set.class_indices.keys())  \n\n# confusionmatrix = confusion_matrix(true_classes, predicted_classes)\nplt.figure(figsize = (5, 5))\nsns.heatmap(confusion_matrix(validation_set.classes, y_pred), cmap = 'Blues', annot = True, cbar = True)\n\n# print(classification_report(true_classes, predicted_classespredictions","metadata":{"_uuid":"9ec56a4b-5829-42d8-969d-c09c59f6caa3","_cell_guid":"00509e31-0440-4ab8-84f4-3c368b508053","collapsed":false,"id":"jUVkMlgObClq","outputId":"2710424b-7d78-469b-c3e6-5e216efaa1e8","tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_accuracy = training_history.history['accuracy']\nvalidation_accuracy = training_history.history['val_accuracy']\n\nplt.figure()\nplt.plot(np.arange(early_stopping.stopped_epoch), training_accuracy[0:early_stopping.stopped_epoch], label = 'Training Set')\nplt.plot(np.arange(early_stopping.stopped_epoch), validation_accuracy[0:early_stopping.stopped_epoch], label = 'Validation Set')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"_uuid":"479b5061-2702-4fb4-affd-eab11b8c1318","_cell_guid":"d48d3b74-5f4a-450d-b49f-5efa997ff6b1","collapsed":false,"id":"S-nd2YMhOXrh","outputId":"464d87a9-428b-44c4-ade2-103d860e97b0","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Évaluation sur les données de test :\nmodel.evaluate(testing_set)\n\n# Léger overfitting ou pas... telle est la question","metadata":{"_uuid":"b0cc23a3-b444-410c-a59b-70922a5d0540","_cell_guid":"263ca191-a0d1-4a5a-acdb-d8a785323cf5","collapsed":false,"id":"n1t8NsEOOYQN","outputId":"e201b49b-e5c4-4147-d4cb-5e5083857984","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########################################################################### ANALYSE - MODEL(2) - FUNC. #########################################","metadata":{"_uuid":"ccbcfce3-1b2a-4cf3-860d-66696ad52dc8","_cell_guid":"af5dce5d-678d-4f61-8491-392be933bf67","collapsed":false,"id":"lYc1zz6PYwyo","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 1 -- Matrice de confusion + rapport de classification (\"présentable\")\n\ndef print_classification_report(testing_set, labels):\n\n  # Prédiction : utilise le jeu de test (testing_set)\n  predictions = model.predict(testing_set)\n  y_pred = tf.argmax(predictions, axis = 1)\n\n  # Calcul et affichage de la matrice de confusion\n  cnf_matrix = confusion_matrix(testing_set.classes, y_pred)\n  classes = range(len(labels))\n  \n  plt.figure(figsize = (12,12))\n  plt.imshow(cnf_matrix, interpolation = 'nearest', cmap = 'Blues')\n  plt.title(\"Matrice de confusion\")\n  plt.colorbar()\n\n  tick_marks = np.arange(len(labels))\n  plt.xticks(tick_marks, labels)\n  plt.yticks(tick_marks, labels)\n\n  for i, j in itertools.product(range(cnf_matrix.shape[0]), \n                                range(cnf_matrix.shape[1])):\n    plt.text(j, i, cnf_matrix[i, j],\n             horizontalalignment = \"center\",\n             color = \"white\" if cnf_matrix[i, j] > ( cnf_matrix.max() / 2) else \"black\")\n\n  plt.ylabel('Vrais labels')\n  plt.xlabel('Labels prédits')\n  plt.show()\n\n  # Rapport de classification \n  report = classification_report(testing_set.classes, y_pred, target_names = labels, output_dict = True)\n\n  df_report = pd.DataFrame(index = list(report.keys())[:-3], columns = list(report[\"BA\"].keys()))\n  for key in list(report.keys())[:-3]:\n    for column in list(report[\"BA\"].keys()):\n      df_report.loc[key, column] = report[key][column]\n  \n  print(\"Classification Report : avant Fine-Tuning\")\n  return display(df_report)\n\nprint_classification_report(testing_set, label_map)\n\n# Ajouter fonction pour enregistrer df_report dans un .csv + transfert sur Drive","metadata":{"_uuid":"f2321cb3-b1de-499f-9c04-fa9677f5bf66","_cell_guid":"4667232b-bc70-4eea-b229-1e3b63a0bef5","collapsed":false,"id":"CL9omvtBYw2_","outputId":"677589e0-3036-4a85-fa00-d10e9da2fdb4","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 2 -- DataFrames pour l'exploitation\npredictions = model.predict(testing_set)\ny_pred = tf.argmax(predictions, axis = 1)\n\n# DF avec le résultat et le label de toutes les images du test :\ndf_results = pd.DataFrame(data = {\"real\":testing_set.classes,\n                                  \"pred\":y_pred, \n                                  \"img_path\":df_test[\"img_path\"]})\n\n# Tri des images : mal classé (df_false), bien classé (df_true):\ndf_false = df_results[df_results[\"real\"] != df_results[\"pred\"]].reset_index(drop = True)\ndf_true = df_results[df_results[\"real\"] == df_results[\"pred\"]].reset_index(drop = True)\n\n# Ajouter fonction pour enregistrer les df_false et df_true dans un .csv + transfert sur Drive","metadata":{"_uuid":"347a661e-85ee-4d41-9cb8-4a21b9fe6081","_cell_guid":"c84583b5-e3a8-41f1-95ad-4af8e03a4fd5","collapsed":false,"id":"Z5JFuaBZW6pD","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 3 -- Grad-CAM sur les images bien classées :\n\nfig = plt.figure(figsize = (20, 40))\ni = 0\n\nfor cell_class in range(n_classes):\n  df_temp = df_true[df_true[\"real\"] == cell_class]\n  id = np.random.choice(df_temp.index, size = 1, replace = False)\n  img_path = df_true.loc[id[0],\"img_path\"]\n \n  big_heatmap, superimposed_img = gradcam(model, img_path, alpha = 0.8, plot = False)\n\n  fig.add_subplot(n_classes,2,i+1)\n  plt.imshow(plt.imread(img_path))\n  plt.title(df_true.loc[id[0],\"real\"])\n\n  fig.add_subplot(n_classes,2,i+2)\n  plt.imshow(superimposed_img)\n\n  i += 2","metadata":{"_uuid":"50fa301f-27d7-478e-9eb3-34d2e1adf69c","_cell_guid":"160b96dd-23a2-4d2b-bc03-fcec5209bada","collapsed":false,"id":"wuRTsqCCW6z8","outputId":"bac46056-2f18-4299-d95a-1d7b4946db98","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 4 -- Exemples d'images mal classées :\n# Exemple : Confusion BNE/SNE : labels 1 et 10\n\nconf_bne_sne = df_false[((df_false[\"real\"] == 1) & (df_false[\"pred\"] == 10)) | ((df_false[\"real\"] == 10) & (df_false[\"pred\"] == 1))]\n\ni = 0\n\nfig = plt.figure(figsize = (15,15))\n\nfor id in np.random.choice(conf_bne_sne.index, size = 5, replace = False):\n  img_path = conf_bne_sne.loc[id,\"img_path\"]\n\n  big_heatmap, superimposed_img = gradcam(model, img_path, alpha = 0.8, plot = False)\n\n  fig.add_subplot(5,2,i+1)\n  plt.imshow(plt.imread(img_path))\n  plt.title(\"Label réel : %s ; Label prédit : %s\"%(list(label_map.keys())[conf_bne_sne.loc[id,\"real\"]],\n                                                   list(label_map.keys())[conf_bne_sne.loc[id,\"pred\"]]))\n  \n  fig.add_subplot(5,2,i+2)\n  plt.imshow(superimposed_img)\n  i = i + 2","metadata":{"_uuid":"8917c13d-a2a5-4314-bf09-3a8919668246","_cell_guid":"e99f9cde-a4c3-4922-9c6b-e295dc252c51","collapsed":false,"id":"PrfHEV6lfSXC","outputId":"93478e4e-1c71-46db-8723-d86f0ce0f8e6","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exemple : Confusion MY/MMY : labels 5 et 7\nconf_my_mmy = df_false[((df_false[\"real\"] == 5) & (df_false[\"pred\"] == 7)) | ((df_false[\"real\"] == 7) & (df_false[\"pred\"] == 5))]\n\nfig = plt.figure(figsize = (30,15))\ni = 0\n\nfor id in np.random.choice(conf_my_mmy.index, size = 5, replace = False):\n\n  img_path = conf_my_mmy.loc[id,\"img_path\"]\n  big_heatmap, superimposed_img = gradcam(model, img_path, alpha = 0.8, plot = False)\n\n  fig.add_subplot(5,2,i+1)\n  plt.imshow(plt.imread(img_path))\n  plt.title(\"Label réel : %s ; Label prédit : %s\"%(list(label_map.keys())[conf_my_mmy.loc[id,\"real\"]],\n                                                   list(label_map.keys())[conf_my_mmy.loc[id,\"pred\"]]))\n  \n  fig.add_subplot(5,2,i+2)\n  plt.imshow(superimposed_img)\n  i += 2","metadata":{"_uuid":"dc364e04-00f1-4a89-99b3-282f534efd91","_cell_guid":"0ef2aa04-c742-4197-8262-674fb00d66bd","collapsed":false,"id":"TZyPeLfBfSyg","outputId":"d45ea013-45aa-4c7b-d53a-ae23c6a14d14","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exemple : Confusion PMY/MY : labels 9 et 7\nconf_pmy_my = df_false[((df_false[\"real\"] == 9) & (df_false[\"pred\"] == 7)) | ((df_false[\"real\"] == 7) & (df_false[\"pred\"] == 9))]\n\nfig = plt.figure(figsize = (30,15))\ni = 0\n\nfor id in np.random.choice(conf_pmy_my.index, size = 5, replace = False):\n\n  img_path = conf_pmy_my.loc[id,\"img_path\"]\n  big_heatmap, superimposed_img = gradcam(model, img_path, alpha = 0.8, plot = False)\n\n  fig.add_subplot(5,2,i+1)\n  plt.imshow(plt.imread(img_path))\n  plt.title(\"Label réel : %s ; Label prédit : %s\"%(list(label_map.keys())[conf_pmy_my.loc[id,\"real\"]],\n                                                   list(label_map.keys())[conf_pmy_my.loc[id,\"pred\"]]))\n  \n  fig.add_subplot(5,2,i+2)\n  plt.imshow(superimposed_img)\n  i += 2","metadata":{"_uuid":"d4d65cea-e6f9-43d6-a569-ec005b3a39b6","_cell_guid":"0043aba8-3f73-43d5-a0b1-007e9c7dcf1b","collapsed":false,"id":"Myt_ny1ufS3v","outputId":"a5f62b49-61c7-4c92-c6fe-db132ffb73b8","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######################################################################### 05/08/21 - FINE TUNING #######################################################################################","metadata":{"_uuid":"fe780df1-312b-4cd3-8db9-f56a147adc25","_cell_guid":"effe4dab-daa7-4fbd-923a-617ac5a4f659","collapsed":false,"id":"NUXbGZZNfS8t","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callbacks\nTON = TerminateOnNaN()\n\ncontrol_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                               factor = 0.1, patience = 3, verbose = 1, mode = 'min', min_lr = 1e-7)\n  \nearly_stopping = EarlyStopping(monitor = \"val_loss\",\n                               patience = 4, mode = 'min', restore_best_weights = True)\n\ncallbacks_list = [TON, control_lr, early_stopping]\n                    \n## Compute weights :\nclass_weights = compute_weights(method = 3)\n\n## Unfreeze Block5 + Compile   (Rq: on pourrait essayer de dégeler block4 + block5)\n\nfor layer in model.layers:\n  if \"block5\" in layer.name:\n    layer.trainable = True\n\noptimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4)\nmodel.compile(optimizer = optimizer,\n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])\n\n## Training :\nepochs = 20\nhistory = model.fit(x = training_set, \n                    epochs = epochs,\n                    callbacks = callbacks_list, \n                    validation_data = validation_set, \n                    class_weight = class_weights)\n## remplacer history par fine_history pour éviter d'écraser history...\n\n### Entraînement sans \"base_model.training = False\" dans VGG (03/08/21): Accuracy : 8.7%, Val Acc : 6.82%, Test Acc : 8.29% => Catastrophe...\n# Pas compris pourquoi...","metadata":{"_uuid":"eefed1e9-f10c-410d-a3b1-d25454c9eaea","_cell_guid":"3ee6217e-10ea-4112-9dd4-6c38b37ae26e","collapsed":false,"id":"cQn0Z4SnN5b-","outputId":"4c977f90-b7cd-4e98-ed9b-3c6b351575fb","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(testing_set)\n# Overfitting léger.","metadata":{"_uuid":"6e0ce54e-e62b-41c2-929f-2d66f3257699","_cell_guid":"2c3d0214-400e-4385-b8a5-ed0a03eaaf6d","collapsed":false,"id":"TnKMsXxJjWYt","outputId":"a7bd80cd-1010-44b9-9e92-1e94837b4723","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Sauvegarde :\nmodel.save(\"/content/drive/MyDrive/Leukopy/VGG19_TL_11/model_fullsave_trainfalse\")","metadata":{"_uuid":"519e8fcf-b95f-4281-ac7d-1f0e98baa51e","_cell_guid":"d13cc392-c5b6-45dc-af8c-c455c2abac67","collapsed":false,"id":"AOSVdtTQ2D_8","outputId":"0041870a-2ff0-4a9f-e564-bc27e88dd813","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_classification_report(testing_set, labels):\n\n  # Prédiction : utilise le jeu de test (testing_set)\n  predictions = model.predict(testing_set)\n  y_pred = tf.argmax(predictions, axis = 1)\n\n  # Calcul et affichage de la matrice de confusion\n  cnf_matrix = confusion_matrix(testing_set.classes, y_pred)\n  classes = range(len(labels))\n  \n  plt.figure(figsize = (12,12))\n  plt.imshow(cnf_matrix, interpolation = 'nearest', cmap = 'Blues')\n  plt.title(\"Matrice de confusion\")\n  plt.colorbar()\n\n  tick_marks = np.arange(len(labels))\n  plt.xticks(tick_marks, labels)\n  plt.yticks(tick_marks, labels)\n\n  for i, j in itertools.product(range(cnf_matrix.shape[0]), \n                                range(cnf_matrix.shape[1])):\n    plt.text(j, i, cnf_matrix[i, j],\n             horizontalalignment = \"center\",\n             color = \"white\" if cnf_matrix[i, j] > ( cnf_matrix.max() / 2) else \"black\")\n\n  plt.ylabel('Vrais labels')\n  plt.xlabel('Labels prédits')\n  plt.show()\n\n  # Rapport de classification \n  report = classification_report(testing_set.classes, y_pred, target_names = labels, output_dict = True)\n\n  df_report = pd.DataFrame(index = list(report.keys())[:-3], columns = list(report[\"BA\"].keys()))\n  for key in list(report.keys())[:-3]:\n    for column in list(report[\"BA\"].keys()):\n      df_report.loc[key, column] = report[key][column]\n  \n  print(\"Classification Report : après fine-tuning\")\n  return display(df_report)\n\nprint_classification_report(testing_set, label_map)\n\n# df_report => csv => Drive","metadata":{"_uuid":"babbfaaf-7793-4999-be20-54a8de2ec942","_cell_guid":"9a4349ee-e7e3-4a88-a6f5-57d095558c25","collapsed":false,"id":"ykbeFycPLN7v","outputId":"8a270d6c-a6d7-4d59-dc6b-1059cf9e2620","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nLe tuning de VGG a amélioré le F1 de toutes les classes sans exception. Toujours des problèmes avec MY/MMY/PMY et BNE/SNE.\nPistes : \n1°/ fine-tuning du 'block4' en plus du 'block5' \nou\n2°/ Procéder en deux temps : d'abord dégeler le block5 et entraîner, puis dégeler le block4 et entraîner.\nRq : je ne remonterais pas plus haut que le block4, sinon on risque de trop spécialiser le modèle sur les jolies images de l'hôpital de Barcelone\nRq2 : très peu d'augmentation de données dans ce run du modèle... on pourrait introduire de légères variations sur : luminosité / netteté / zoom\n\"\"\"","metadata":{"_uuid":"133b0dca-ecb8-417d-bc30-06f9279dd405","_cell_guid":"2d3ddd11-258f-4e35-8998-6bd2660f32e6","collapsed":false,"id":"2mcp9M1LiNka","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 2 -- DataFrames pour l'exploitation\npredictions = model.predict(testing_set)\ny_pred = tf.argmax(predictions, axis = 1)\n\n# DF avec le résultat et le label de toutes les images du test :\ndf_results = pd.DataFrame(data = {\"real\":testing_set.classes,\n                                  \"pred\":y_pred, \n                                  \"img_path\":df_test[\"img_path\"]})\n\n# Tri des images : mal classé (df_false), bien classé (df_true):\ndf_false = df_results[df_results[\"real\"] != df_results[\"pred\"]].reset_index(drop = True)\ndf_true = df_results[df_results[\"real\"] == df_results[\"pred\"]].reset_index(drop = True)","metadata":{"_uuid":"1d157766-a9a7-495c-be09-50548adadf63","_cell_guid":"553b489a-a721-409b-a76e-9bdb55b210d0","collapsed":false,"id":"LFlF7H4MN7qt","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (20, 40))\ni = 0\n\nfor cell_class in range(n_classes):\n  df_temp = df_true[df_true[\"real\"] == cell_class]\n  id = np.random.choice(df_temp.index, size = 1, replace = False)\n  img_path = df_true.loc[id[0],\"img_path\"]\n \n  big_heatmap, superimposed_img = gradcam(model, img_path, alpha = 0.8, plot = False)\n\n  fig.add_subplot(n_classes,2,i+1)\n  plt.imshow(plt.imread(img_path))\n  plt.title(df_true.loc[id[0],\"real\"])\n\n  fig.add_subplot(n_classes,2,i+2)\n  plt.imshow(superimposed_img)\n\n  i += 2","metadata":{"_uuid":"c4afc4e4-de65-4d7b-bdb3-07b3693ebd02","_cell_guid":"a9a10fc6-797a-4531-aa2c-fb86d1e0a88a","collapsed":false,"id":"cVND6ogGOFgp","outputId":"2fd2fb90-3ac5-46b7-9ecb-c79a9fab7a8d","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 4 -- Exemples d'images mal classées :\n# Exemple : Confusion BNE/SNE : labels 1 et 10\n\nconf_bne_sne = df_false[((df_false[\"real\"] == 1) & (df_false[\"pred\"] == 10)) | ((df_false[\"real\"] == 10) & (df_false[\"pred\"] == 1))]\n\ni = 0\n\nfig = plt.figure(figsize = (15,15))\n\nfor id in np.random.choice(conf_bne_sne.index, size = 5, replace = False):\n  img_path = conf_bne_sne.loc[id,\"img_path\"]\n\n  big_heatmap, superimposed_img = gradcam(model, img_path, alpha = 0.8, plot = False)\n\n  fig.add_subplot(5,2,i+1)\n  plt.imshow(plt.imread(img_path))\n  plt.title(\"Label réel : %s ; Label prédit : %s\"%(list(label_map.keys())[conf_bne_sne.loc[id,\"real\"]],\n                                                   list(label_map.keys())[conf_bne_sne.loc[id,\"pred\"]]))\n  \n  fig.add_subplot(5,2,i+2)\n  plt.imshow(superimposed_img)\n  i = i + 2","metadata":{"_uuid":"0c127371-34b8-4050-9466-4112cfb6aa88","_cell_guid":"011d442e-3dfc-4346-8984-030cf81c4909","collapsed":false,"id":"qXc3IlxpcbqJ","outputId":"6a4fce25-94e2-4ff0-ed02-314e0d76fbc1","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exemple : Confusion MY/MMY : labels 5 et 7\nconf_my_mmy = df_false[((df_false[\"real\"] == 5) & (df_false[\"pred\"] == 7)) | ((df_false[\"real\"] == 7) & (df_false[\"pred\"] == 5))]\n\nfig = plt.figure(figsize = (30,15))\ni = 0\n\nfor id in np.random.choice(conf_my_mmy.index, size = 5, replace = False):\n\n  img_path = conf_my_mmy.loc[id,\"img_path\"]\n  big_heatmap, superimposed_img = gradcam(model, img_path, alpha = 0.8, plot = False)\n\n  fig.add_subplot(5,2,i+1)\n  plt.imshow(plt.imread(img_path))\n  plt.title(\"Label réel : %s ; Label prédit : %s\"%(list(label_map.keys())[conf_my_mmy.loc[id,\"real\"]],\n                                                   list(label_map.keys())[conf_my_mmy.loc[id,\"pred\"]]))\n  \n  fig.add_subplot(5,2,i+2)\n  plt.imshow(superimposed_img)\n  i += 2","metadata":{"_uuid":"3504672c-12c9-4324-a3c8-b77d56e49df7","_cell_guid":"40b24101-b7be-4740-b7af-20117ff6f86c","collapsed":false,"id":"HHyE18lZcfpd","outputId":"76ce9477-726e-4963-e1ca-205738cc231b","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exemple : Confusion PMY/MY : labels 9 et 7\nconf_pmy_my = df_false[((df_false[\"real\"] == 9) & (df_false[\"pred\"] == 7)) | ((df_false[\"real\"] == 7) & (df_false[\"pred\"] == 9))]\n\nfig = plt.figure(figsize = (30,15))\ni = 0\n\nfor id in np.random.choice(conf_pmy_my.index, size = 5, replace = False):\n\n  img_path = conf_pmy_my.loc[id,\"img_path\"]\n  big_heatmap, superimposed_img = gradcam(model, img_path, alpha = 0.8, plot = False)\n\n  fig.add_subplot(5,2,i+1)\n  plt.imshow(plt.imread(img_path))\n  plt.title(\"Label réel : %s ; Label prédit : %s\"%(list(label_map.keys())[conf_pmy_my.loc[id,\"real\"]],\n                                                   list(label_map.keys())[conf_pmy_my.loc[id,\"pred\"]]))\n  \n  fig.add_subplot(5,2,i+2)\n  plt.imshow(superimposed_img)\n  i += 2","metadata":{"_uuid":"bf744986-8444-4633-a72c-5a741171576d","_cell_guid":"eaf30340-5acb-4d46-9912-1dff2f5a917a","collapsed":false,"id":"Fr2D9fRocl82","outputId":"898acdf5-2a0b-46bf-c3a3-62f1a1262840","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nOn a encore du travail pour ce qui relève de l'interprétabilité du modèle. Grad-CAM montre que le modèle se concentre sur le centre de l'image,\nce qui est positif, mais il ne prend pas en compte la totalité de la cellule, seulement une partie (et qui n'est pas nécessairement le noyau)\nPistes :\n- entraîner le modèle sur les images découpées \"C_NMC_2019 Dataset\" et comparer les Grad-CAM / performances\n\n- tenter un clustering / une PCA en sortie de modèle, puis colorer les images mal classées sur la figure produite par le clustering / la PCA\n\"\"\"","metadata":{"_uuid":"5fb2c40c-93b8-4abc-b6af-3296d67aa918","_cell_guid":"73cd5f4d-e6a8-4dec-8f15-e16e2454ec80","collapsed":false,"id":"bBybmdFCeE3z","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\" \nAutre : \n- on pourrait intégrer les fonctions Grad-CAM à leuko_lib ... ou faire un module à part.","metadata":{"_uuid":"db8ebc99-ed14-48a1-a45b-747d3c8916d5","_cell_guid":"6b53a0b6-d986-48c0-ac16-f6e3821dad0b","collapsed":false,"id":"q1zlu578lVd2","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}