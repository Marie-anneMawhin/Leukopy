{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donne à Colab un accès à un Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57990d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17253150",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copie locale des fichiers (tous dans le même dossier, changer le chemin d'accès)\n",
    "#!cp -r \"/content/drive/MyDrive/Leukopy/Data_PBC/Data_PBC.zip\" .\n",
    "#!unzip PBC_dataset_normal_DIB.zip\n",
    "\n",
    "## Copie locale des fichiers (sous-répertoires training et testing => c'était utilisé avec flow_from_directory)\n",
    "!cp -r \"/content/drive/MyDrive/Leukopy/Data/Data.zip\" .\n",
    "!unzip Data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Toutes les données dans un seul et même dossier :\n",
    "# liste = glob.glob('./Data_PBC/*/*.jpg')\n",
    "# liste = list(map(lambda x : [x, x.split('/')[2]], liste))\n",
    "# df = pd.DataFrame(liste, columns = ['path', 'label'])\n",
    "\n",
    "#df, df_test = train_test_split(df, test_size = 0.2)\n",
    "#df_train, df_valid = train_test_split(df, test_size = 0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ed498",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Données pré-séparées dans deux dossiers, training et testing :\n",
    "# Chemin d'accès aux images\n",
    "liste_train = glob.glob('./Data/training/*/*.jpg')\n",
    "liste_test = glob.glob('./Data/testing/*/*.jpg')\n",
    "\n",
    "# Extrait le label de chaque image\n",
    "liste_train = list(map(lambda x : [x, x.split('/')[3]], liste_train))\n",
    "liste_test = list(map(lambda x : [x, x.split('/')[3]], liste_test))\n",
    "\n",
    "# DataFrames\n",
    "df_train = pd.DataFrame(liste_train, columns = ['path', 'label'])\n",
    "df_test = pd.DataFrame(liste_test, columns = ['path', 'label'])\n",
    "\n",
    "# Jeu de validation\n",
    "df_train, df_valid = train_test_split(df_train, test_size = 0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21da640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "batch_size = 32\n",
    "img_height  = 256\n",
    "img_width = 256\n",
    "\n",
    "# Augmentation seulement sur le jeu d'entraînement. On normalise toutes les images.\n",
    "train_generator = ImageDataGenerator(rotation_range = 90,\n",
    "                                     horizontal_flip = True, \n",
    "                                     vertical_flip = True, \n",
    "                                     rescale = 1./255)\n",
    "valid_generator = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Batchs, redimensionnement, chargement des images\n",
    "training_set = train_generator.flow_from_dataframe(df_train, \n",
    "                                                   directory = None, # utilise x_col\n",
    "                                                   x_col = 'path', \n",
    "                                                   y_col = 'label',\n",
    "                                                   target_size = (img_height, img_width), \n",
    "                                                   color_mode = 'rgb',\n",
    "                                                   classes = None,   # utilise y_col\n",
    "                                                   class_mode = 'categorical', \n",
    "                                                   batch_size = batch_size, \n",
    "                                                   shuffle = True)\n",
    "\n",
    "validation_set = valid_generator.flow_from_dataframe(df_valid, \n",
    "                                                     directory = None, # utilise x_col\n",
    "                                                     x_col = 'path', \n",
    "                                                     y_col = 'label',\n",
    "                                                     target_size = (img_height, img_width), \n",
    "                                                     color_mode = 'rgb',\n",
    "                                                     classes = None,   # utilise y_col\n",
    "                                                     class_mode = 'categorical', \n",
    "                                                     batch_size = batch_size, \n",
    "                                                     shuffle = True)\n",
    "\n",
    "testing_set = test_generator.flow_from_dataframe(df_test, \n",
    "                                                 directory = None, # utilise x_col\n",
    "                                                 x_col = 'path', \n",
    "                                                 y_col = 'label',\n",
    "                                                 target_size = (img_height, img_width),\n",
    "                                                 color_mode = 'rgb',\n",
    "                                                 classes = None,   # utilise y_col\n",
    "                                                 class_mode = 'categorical', \n",
    "                                                 batch_size = batch_size, \n",
    "                                                 shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correspondance indices/labels (ordre alphanumérique):\n",
    "print('Train :', training_set.class_indices)\n",
    "print('Valid :', validation_set.class_indices)\n",
    "print('Test  :', testing_set.class_indices)\n",
    "\n",
    "label_map = training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd14f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle LeNet\n",
    "\n",
    "model = Sequential(\n",
    "    [layers.Conv2D(filters = 30,\n",
    "                   kernel_size = (5,5),\n",
    "                   activation = 'relu',\n",
    "                   padding = 'valid', \n",
    "                   input_shape = (img_height, img_width, 3)),\n",
    "     layers.MaxPooling2D(pool_size = (2,2)),\n",
    "     layers.Conv2D(filters = 16,\n",
    "                   kernel_size = (3,3),\n",
    "                   activation = 'relu',\n",
    "                   padding = 'valid'),\n",
    "     layers.MaxPooling2D(pool_size = (2,2)),\n",
    "     layers.Dropout(rate = 0.2),\n",
    "     layers.Flatten(),\n",
    "     layers.Dense(units = 128, activation = 'relu'),\n",
    "     layers.Dense(units = 8, activation  = 'softmax')\n",
    "     ])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_set, epochs = 20, validation_data = validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba80b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(20), training_accuracy, label = 'Training Set')\n",
    "plt.plot(np.arange(20), validation_accuracy, label = 'Validation Set')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim([0,19])\n",
    "plt.ylim([0.5,1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle sur Drive\n",
    "model.save(\"/content/drive/MyDrive/Leukopy/LeNetModel/model_lenet_augment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
